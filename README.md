# Agent Local com RAG - Guia Completo

Um **agent inteligente local** que:
- üìö Consulta seus documentos (RAG)
- üîó Chama APIs e endpoints
- üìù Manipula arquivos
- üêõ Debugga e resolve problemas
- üîÑ Itera automaticamente para a√ß√µes complexas

## Setup R√°pido

### 1. Instalar Ollama
```bash
# macOS
brew install ollama

# Ou fa√ßa download em: https://ollama.ai
```

### 2. Baixar modelo Mistral (ou outro)
```bash
ollama pull mistral
ollama pull nomic-embed-text  # Para embeddings
```

### 3. Iniciar servidor Ollama
```bash
ollama serve
# Roda em http://localhost:11434
```

### 4. Em outro terminal, instalar depend√™ncias
```bash
pip install -r requirements.txt
```

### 5. Executar agent

**Modo com query direta:**
```bash
python main.py "Qual √© o status da API de usu√°rios?"
```

**Modo interativo:**
```bash
python main.py
```

## Exemplos de Uso

### Exemplo 1: Consultar documenta√ß√£o
```
Voc√™: Como autenticar na API?
Agent: [consulta docs] ‚Üí Responde com informa√ß√µes dos documentos
```

### Exemplo 2: Chamar API e processar resposta
```
Voc√™: Busque os dados do usu√°rio ID 123 em https://api.example.com/users/123
Agent: [chama endpoint] ‚Üí [processa JSON] ‚Üí Exibe resultado
```

### Exemplo 3: Resolver problema
```
Voc√™: Recebi erro 401 ao chamar a API, o que fazer?
Agent: [busca docs] ‚Üí [analisa erro] ‚Üí Sugere solu√ß√µes
```

### Exemplo 4: Criar arquivo baseado em API
```
Voc√™: Fa√ßa uma requisi√ß√£o GET para https://api.example.com/data e salve o resultado em output.json
Agent: [chama API] ‚Üí [valida JSON] ‚Üí [salva arquivo] ‚Üí Confirma
```

## Estrutura do Projeto

```
tale/
‚îú‚îÄ‚îÄ requirements.txt      # Depend√™ncias Python
‚îú‚îÄ‚îÄ main.py              # CLI principal
‚îú‚îÄ‚îÄ agent.py             # L√≥gica do agent
‚îú‚îÄ‚îÄ rag.py               # Processamento de documentos
‚îú‚îÄ‚îÄ tools.py             # Tools/Actions dispon√≠veis
‚îú‚îÄ‚îÄ docs/                # Seus documentos (criar esta pasta)
‚îÇ   ‚îú‚îÄ‚îÄ api.md           # Documenta√ß√£o de API
‚îÇ   ‚îú‚îÄ‚îÄ guide.pdf        # Guias
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ vector_store/        # √çndice FAISS (criado automaticamente)
```

## Adicionar Documentos

1. Crie uma pasta `./docs/`
2. Adicione seus arquivos (PDF, TXT, MD, DOCX)
3. Execute o agent - ele carregar√° automaticamente

```bash
mkdir -p docs
cp seu-documento.pdf docs/
python main.py "pergunta sobre seu documento"
```

## Adicionar Novas Tools

Abra `tools.py` e crie uma nova classe:

```python
class MyTool:
    @staticmethod
    def my_action(param1: str) -> ToolResult:
        """Descri√ß√£o da a√ß√£o"""
        try:
            # Sua l√≥gica aqui
            return ToolResult(success=True, data=resultado)
        except Exception as e:
            return ToolResult(success=False, data=None, error=str(e))
```

Depois registre em `TOOLS`:
```python
TOOLS = {
    ...
    "mytool": MyTool,
}
```

Use no agent:
```
<tool>{"tool": "mytool", "action": "my_action", "param1": "valor"}</tool>
```

## Configura√ß√µes

### Trocar modelo de LLM
```python
agent = Agent(model_name="neural-chat")  # ou "llama2", "orca", etc
```

### Ajustar RAG
```python
# Em rag.py, m√©todo chunk_documents()
agent.doc_processor.chunk_documents(
    chunk_size=2000,      # Tamanho dos chunks
    chunk_overlap=400     # Sobreposi√ß√£o
)
```

### Aumentar itera√ß√µes
```python
agent.max_iterations = 20  # Padr√£o: 10
```

## Troubleshooting

### Erro: "Connection refused"
```bash
# Ollama n√£o est√° rodando, execute:
ollama serve
```

### Erro: "Model not found"
```bash
# Baixe o modelo:
ollama pull mistral
ollama pull nomic-embed-text
```

### Documentos n√£o carregam
```bash
# Verificar pasta docs/
ls -la docs/

# Se vazia, criar exemplos:
python main.py  # Cria exemplos automaticamente
```

### Agent muito lento
- Reduza `chunk_size` em `rag.py`
- Use modelo mais leve: `ollama pull phi` (2GB)
- Reduza `k` em `search()`: `k=2` em vez de `k=3`

## Seguran√ßa & Privacidade

- ‚úÖ Tudo roda **localmente**
- ‚úÖ Nenhum dado √© enviado para cloud
- ‚úÖ Controle total sobre documentos
- ‚ö†Ô∏è Proteja sua pasta `docs/` e `.env` (se usar)

## Pr√≥ximas Melhorias

- [ ] Integra√ß√£o com mais modelos locais
- [ ] Cache de embeddings
- [ ] Web UI com Streamlit
- [ ] Logging e auditoria
- [ ] Suporte a banco de dados (SQLite)
- [ ] Agentes especializados (finance, devops, etc)

## Refer√™ncias

- [Ollama](https://ollama.ai)
- [LangChain](https://langchain.com)
- [FAISS](https://github.com/facebookresearch/faiss)
- [RAG Pattern](https://python.langchain.com/docs/use_cases/question_answering/)

---

**Desenvolvido com ‚ù§Ô∏è para automa√ß√£o local**

